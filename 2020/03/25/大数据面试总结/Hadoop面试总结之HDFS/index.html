<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="大数据面试总结/Hadoop面试总结之HDFS"><meta name="keywords" content=""><meta name="author" content="fenglin"><meta name="copyright" content="fenglin"><title>大数据面试总结/Hadoop面试总结之HDFS | 枫林晔雪的博客</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  }
} </script><meta name="generator" content="Hexo 4.2.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop面试总结之HDFS"><span class="toc-number">1.</span> <span class="toc-text">Hadoop面试总结之HDFS</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1、集群的最主要瓶颈"><span class="toc-number">1.1.</span> <span class="toc-text">1、集群的最主要瓶颈</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2、Hadoop运行模式"><span class="toc-number">1.2.</span> <span class="toc-text">2、Hadoop运行模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3、Hadoop生态圈的组件并做简要描述"><span class="toc-number">1.3.</span> <span class="toc-text">3、Hadoop生态圈的组件并做简要描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4、解释“hadoop”和“hadoop-生态系统”两个概念"><span class="toc-number">1.4.</span> <span class="toc-text">4、解释“hadoop”和“hadoop 生态系统”两个概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5、请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么"><span class="toc-number">1.5.</span> <span class="toc-text">5、请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6、HDFS-中的-block-默认保存几份？"><span class="toc-number">1.6.</span> <span class="toc-text">6、HDFS 中的 block 默认保存几份？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7、HDFS-默认-BlockSize-是多大？"><span class="toc-number">1.7.</span> <span class="toc-text">7、HDFS 默认 BlockSize 是多大？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8、负责HDFS数据存储的是哪一部分？"><span class="toc-number">1.8.</span> <span class="toc-text">8、负责HDFS数据存储的是哪一部分？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9、SecondaryNameNode的目的是什么？"><span class="toc-number">1.9.</span> <span class="toc-text">9、SecondaryNameNode的目的是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10、文件大小设置，增大有什么影响？"><span class="toc-number">1.10.</span> <span class="toc-text">10、文件大小设置，增大有什么影响？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11、HDFS的存储机制-读写过程-重要"><span class="toc-number">1.11.</span> <span class="toc-text">11、HDFS的存储机制&#x2F;读写过程 (重要)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12、secondary-namenode工作机制"><span class="toc-number">1.12.</span> <span class="toc-text">12、secondary namenode工作机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13、NameNode与SecondaryNameNode-的区别与联系？"><span class="toc-number">1.13.</span> <span class="toc-text">13、NameNode与SecondaryNameNode 的区别与联系？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14、HDFS组成架构"><span class="toc-number">1.14.</span> <span class="toc-text">14、HDFS组成架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15、HAnamenode-是如何工作的"><span class="toc-number">1.15.</span> <span class="toc-text">15、HAnamenode 是如何工作的?</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="http://touxiangkong.com/uploads/allimg/2019062616/muputp0kgmw.jpg"></div><div class="author-info__name text-center">fenglin</div><div class="author-info__description text-center">热爱生活，热爱学习</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">11</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">5</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">4</span></a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://images7.alphacoders.com/753/753592.png)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">枫林晔雪的博客</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">首页</a><a class="site-page" href="/archives">时间线</a><a class="site-page" href="/tags">标签</a><a class="site-page" href="/categories">分类</a></span><span class="pull-right"></span></div><div id="post-info"><div id="post-title">大数据面试总结/Hadoop面试总结之HDFS</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-03-25</time></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="Hadoop面试总结之HDFS"><a href="#Hadoop面试总结之HDFS" class="headerlink" title="Hadoop面试总结之HDFS"></a>Hadoop面试总结之HDFS</h2><h3 id="1、集群的最主要瓶颈"><a href="#1、集群的最主要瓶颈" class="headerlink" title="1、集群的最主要瓶颈"></a>1、集群的最主要瓶颈</h3><p>&emsp; 磁盘IO  </p>
<h3 id="2、Hadoop运行模式"><a href="#2、Hadoop运行模式" class="headerlink" title="2、Hadoop运行模式"></a>2、Hadoop运行模式</h3><p>&emsp; 单机版、伪分布式模式、完全分布式模式  </p>
<h3 id="3、Hadoop生态圈的组件并做简要描述"><a href="#3、Hadoop生态圈的组件并做简要描述" class="headerlink" title="3、Hadoop生态圈的组件并做简要描述"></a>3、Hadoop生态圈的组件并做简要描述</h3><p>&emsp; 1）Zookeeper：是一个开源的分布式应用程序协调服务,基于zookeeper可以实现同步服务，配置维护，命名服务。<br>&emsp; 2）Flume：一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。<br>&emsp; 3）Hbase：是一个分布式的、面向列的开源数据库, 利用Hadoop HDFS作为其存储系统。<br>&emsp; 4）Hive：基于Hadoop的一个数据仓库工具，可以将结构化的数据档映射为一张数据库表，并提供简单的sql 查询功能，可以将sql语句转换为MapReduce任务进行运行。<br>&emsp; 5）Sqoop：将一个关系型数据库中的数据导进到Hadoop的 HDFS中，也可以将HDFS的数据导进到关系型数据库中。 </p>
<h3 id="4、解释“hadoop”和“hadoop-生态系统”两个概念"><a href="#4、解释“hadoop”和“hadoop-生态系统”两个概念" class="headerlink" title="4、解释“hadoop”和“hadoop 生态系统”两个概念"></a>4、解释“hadoop”和“hadoop 生态系统”两个概念</h3><p>&emsp; Hadoop是指Hadoop框架本身，包括HDFS，MapReduce，yarn；hadoop生态系统，不仅包含hadoop，还包括保证hadoop框架正常高效运行其他框架，比如zookeeper、Flume、Hbase、Hive、Sqoop等辅助框架。  </p>
<h3 id="5、请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么"><a href="#5、请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么" class="headerlink" title="5、请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么?"></a>5、请列出正常工作的Hadoop集群中Hadoop都分别需要启动哪些进程，它们的作用分别是什么?</h3><p>&emsp; 1）NameNode：它hadoop中的主服务器，管理文件系统名称空间和对集群中存储的文件的访问，保存元数据metadate。<br>&emsp; 2）SecondaryNameNode：提供周期检查点和清理任务。帮助NN合并editslog并生成新的fsimage，减少NN重启时间。 其次它也是namenode的冗余守护进程。<br>&emsp; 3）DataNode：管理数据节点的数据。<br>&emsp; 4）ResourceManager（JobTracker）：RM负责资源管理。<br>&emsp; 5）NodeManager：（TaskTracker）执行任务。<br>&emsp; 6）DFSZKFailoverController：高可用时它负责监控NN的状态，并及时的把状态信息写入ZK。它通过一个独立线程周期性的调用NN上的一个特定接口来获取NN的健康状态。FC也有选择谁作为Active NN的权利，因为最多只有两个节点，目前选择策略还比较简单（先到先得，轮换）。<br>&emsp; 7）JournalNode：高可用情况下存放namenode的editlog文件。保证active NN和standby NN的数据一致。</p>
<h3 id="6、HDFS-中的-block-默认保存几份？"><a href="#6、HDFS-中的-block-默认保存几份？" class="headerlink" title="6、HDFS 中的 block 默认保存几份？"></a>6、HDFS 中的 block 默认保存几份？</h3><p>&emsp; 默认保存3份  </p>
<h3 id="7、HDFS-默认-BlockSize-是多大？"><a href="#7、HDFS-默认-BlockSize-是多大？" class="headerlink" title="7、HDFS 默认 BlockSize 是多大？"></a>7、HDFS 默认 BlockSize 是多大？</h3><p>128 MB (Hadoop 2. x)   </p>
<p>64 MB (Hadoop 1. x)</p>
<h3 id="8、负责HDFS数据存储的是哪一部分？"><a href="#8、负责HDFS数据存储的是哪一部分？" class="headerlink" title="8、负责HDFS数据存储的是哪一部分？"></a>8、负责HDFS数据存储的是哪一部分？</h3><p>&emsp; DataNode负责数据存储  </p>
<h3 id="9、SecondaryNameNode的目的是什么？"><a href="#9、SecondaryNameNode的目的是什么？" class="headerlink" title="9、SecondaryNameNode的目的是什么？"></a>9、SecondaryNameNode的目的是什么？</h3><p>&emsp; 与NameNode交互，定期合并editlog和fsimage，减少NameNode 重启时间  </p>
<h3 id="10、文件大小设置，增大有什么影响？"><a href="#10、文件大小设置，增大有什么影响？" class="headerlink" title="10、文件大小设置，增大有什么影响？"></a>10、文件大小设置，增大有什么影响？</h3><p>&emsp; HDFS中的文件在物理上是分块存储（block），块的大小可以通过配置参数( dfs.blocksize)来规定，默认大小在hadoop2.x版本中是128M，hadoop1.x中是64M。<br>&emsp; <strong>思考：为什么块的大小不能设置的太小，也不能设置的太大？</strong><br>&emsp; HDFS的块比磁盘的块大，其目的是为了<strong>最小化寻址开销</strong>。如果块设置得足够大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。<br>因而，<strong>传输一个由多个块组成的文件的时间取决于磁盘传输速率</strong>。<br>    HDFS中寻址时间约为10ms， 经大量测试发现，寻址时间为传输时间的1%时，为最佳状态；<br>    假定传输速率为100MB/s，为了使寻址时间仅占传输时间的1%，我们要将块大小设置约为100MB。默认的块大小128MB。<br>&emsp; 块的大小：10ms/0.01×100M/s = 100M，如图  </p>
<p><img src="https://github.com/Dr11ft/BigDataGuide/raw/master/Pics/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98Pics/HDFS%E5%9D%97.png" alt="img"></p>
<p>&emsp; 增加文件块大小，需要增加磁盘的传输速率。  </p>
<h3 id="11、HDFS的存储机制-读写过程-重要"><a href="#11、HDFS的存储机制-读写过程-重要" class="headerlink" title="11、HDFS的存储机制/读写过程 (重要)"></a>11、HDFS的存储机制/读写过程 (重要)</h3><p>&emsp; HDFS存储机制，包括HDFS的<strong>写入数据过程</strong>和<strong>读取数据过程</strong>两部分<br>&emsp; <strong>HDFS写数据过程</strong>  </p>
<p><img src="https://github.com/Dr11ft/BigDataGuide/raw/master/Pics/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98Pics/HDFS%E5%86%99%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png" alt="img"></p>
<p>&emsp; 1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。<br>&emsp; 2）NameNode返回是否可以上传。<br>&emsp; 3）客户端请求第一个 block上传到哪几个datanode服务器上。<br>&emsp; 4）NameNode返回3个datanode节点，分别为dn1、dn2、dn3。<br>&emsp; 5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。<br>&emsp; 6）dn1、dn2、dn3逐级应答客户端。<br>&emsp; 7）客户端开始往dn1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。<br>&emsp; 8）当一个block传输完成之后，客户端再次请求NameNode上传第二个block的服务器。（重复执行3-7步）。  </p>
<p>&emsp; <strong>HDFS读数据过程</strong>  </p>
<p><img src="https://github.com/Dr11ft/BigDataGuide/raw/master/Pics/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98Pics/HDFS%E8%AF%BB%E6%95%B0%E6%8D%AE%E6%B5%81%E7%A8%8B.png" alt="img"></p>
<p>&emsp; 1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。<br>&emsp; 2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。<br>&emsp; 3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以packet为单位来做校验）。<br>&emsp; 4）客户端以packet为单位接收，先在本地缓存，然后写入目标文件。  </p>
<h3 id="12、secondary-namenode工作机制"><a href="#12、secondary-namenode工作机制" class="headerlink" title="12、secondary namenode工作机制"></a>12、secondary namenode工作机制</h3><p><img src="https://github.com/Dr11ft/BigDataGuide/raw/master/Pics/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98Pics/secondary%20namenode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6.png" alt="img"></p>
<p><strong>1）第一阶段：NameNode启动</strong><br>&emsp; （1）第一次启动NameNode格式化后，创建fsimage和edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。<br>&emsp; （2）客户端对元数据进行增删改的请求。<br>&emsp; （3）NameNode记录操作日志，更新滚动日志。<br>&emsp; （4）NameNode在内存中对数据进行增删改查。<br><strong>2）第二阶段：Secondary NameNode工作</strong><br>&emsp; （1）Secondary NameNode询问NameNode是否需要checkpoint。直接带回NameNode是否检查结果。<br>&emsp; （2）Secondary NameNode请求执行checkpoint。<br>&emsp; （3）NameNode滚动正在写的edits日志。<br>&emsp; （4）将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。<br>&emsp; （5）Secondary NameNode加载编辑日志和镜像文件到内存，并合并。<br>&emsp; （6）生成新的镜像文件fsimage.chkpoint。<br>&emsp; （7）拷贝fsimage.chkpoint到NameNode。<br>&emsp; （8）NameNode将fsimage.chkpoint重新命名成fsimage。</p>
<h3 id="13、NameNode与SecondaryNameNode-的区别与联系？"><a href="#13、NameNode与SecondaryNameNode-的区别与联系？" class="headerlink" title="13、NameNode与SecondaryNameNode 的区别与联系？"></a>13、NameNode与SecondaryNameNode 的区别与联系？</h3><p> 1）区别<br>&emsp; （1）NameNode负责管理整个文件系统的元数据，以及每一个路径（文件）所对应的数据块信息。<br>&emsp; （2）SecondaryNameNode主要用于定期合并命名空间镜像和命名空间镜像的编辑日志。<br>2）联系：<br>&emsp; （1）SecondaryNameNode中保存了一份和namenode一致的镜像文件（fsimage）和编辑日志（edits）。<br>&emsp; （2）在主namenode发生故障时（假设没有及时备份数据），可以从SecondaryNameNode恢复数据。  </p>
<h3 id="14、HDFS组成架构"><a href="#14、HDFS组成架构" class="headerlink" title="14、HDFS组成架构"></a>14、HDFS组成架构</h3><p><img src="https://github.com/Dr11ft/BigDataGuide/raw/master/Pics/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98Pics/HDFS%E7%BB%84%E6%88%90%E6%9E%B6%E6%9E%84.png" alt="img"></p>
<p>架构主要由四个部分组成，分别为<strong>HDFS Client、NameNode、DataNode和Secondary NameNode</strong>。下面我们分别介绍这四个组成部分。<br>1）Client：就是客户端。<br>&emsp; （1）文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行存储；<br>&emsp; （2）与NameNode交互，获取文件的位置信息；<br>&emsp; （3）与DataNode交互，读取或者写入数据；<br>&emsp; （4）Client提供一些命令来管理HDFS，比如启动或者关闭HDFS；<br>&emsp; （5）Client可以通过一些命令来访问HDFS；<br>2）NameNode：就是Master，它是一个主管、管理者。<br>&emsp; （1）管理HDFS的名称空间；<br>&emsp; （2）管理数据块（Block）映射信息；<br>&emsp; （3）配置副本策略；<br>&emsp; （4）处理客户端读写请求。<br>3）DataNode：就是Slave。NameNode下达命令，DataNode执行实际的操作。<br>&emsp; （1）存储实际的数据块；<br>&emsp; （2）执行数据块的读/写操作。<br>4）Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。<br>&emsp; （1）辅助NameNode，分担其工作量；<br>&emsp; （2）定期合并Fsimage和Editslog，并推送给NameNode；<br>&emsp; （3）在紧急情况下，可辅助恢复NameNode，但会造成一定的数据丢失。  </p>
<h3 id="15、HAnamenode-是如何工作的"><a href="#15、HAnamenode-是如何工作的" class="headerlink" title="15、HAnamenode 是如何工作的?"></a>15、HAnamenode 是如何工作的?</h3><img src="https://github.com/Dr11ft/BigDataGuide/raw/master/Pics/Hadoop%E9%9D%A2%E8%AF%95%E9%A2%98Pics/HAnamenode%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6.png">

<p>ZKFailoverController主要职责<br>&emsp; 1）健康监测：周期性的向它监控的NN发送健康探测命令，从而来确定某个NameNode是否处于健康状态，如果机器宕机，心跳失败，那么zkfc就会标记它处于一个不健康的状态。<br>&emsp; 2）会话管理：如果NN是健康的，zkfc就会在zookeeper中保持一个打开的会话，如果NameNode同时还是Active状态的，那么zkfc还会在Zookeeper中占有一个类型为短暂类型的znode，当这个NN挂掉时，这个znode将会被删除，然后备用的NN，将会得到这把锁，升级为主NN，同时标记状态为Active。<br>&emsp; 3）当宕机的NN新启动时，它会再次注册zookeper，发现已经有znode锁了，便会自动变为Standby状态，如此往复循环，保证高可靠，需要注意，目前仅仅支持最多配置2个NN。<br>&emsp; 4）master选举：如上所述，通过在zookeeper中维持一个短暂类型的znode，来实现抢占式的锁机制，从而判断那个NameNode为Active状态  </p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">fenglin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://xyzstorm.github.io/2020/03/25/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/Hadoop%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%E4%B9%8BHDFS/">https://xyzstorm.github.io/2020/03/25/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/Hadoop%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%E4%B9%8BHDFS/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://xyzstorm.github.io">枫林晔雪的博客</a>！</span></div></div><div class="post-meta__tag-list"></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/03/25/%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93/Hadoop%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%E4%B9%8BMapReduce/"><i class="fa fa-chevron-left">  </i><span>大数据面试总结/Hadoop面试总结之MapReduce</span></a></div><div class="next-post pull-right"><a href="/2020/03/25/SparkStreaming%20%E8%BE%93%E5%87%BA%E7%AE%97%E5%AD%90--foreachRDD/"><span>SparkStreaming 输出算子--foreachRDD</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer class="footer-bg" style="background-image: url(https://images7.alphacoders.com/753/753592.png)"><div class="layout" id="footer"><div class="copyright">&copy;2020 By fenglin</div><div class="framework-info"><span>驱动 - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script></body></html>